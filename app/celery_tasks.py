from celery import Celery
from app.database import DatabaseManager
from app.services.harvester import run_full_pipeline
from app.moissonneur import fetch_openalex_articles, fetch_oai_pmh_articles, reanalyser_tous_les_articles
from app.logger import logger
from app.nlp_grobid import detecter_controverse_via_tei

# =========================================
# üîß CONFIGURATION GLOBALE
# =========================================
BROKER_URL = "redis://redis_mb2:6379/0"
BACKEND_URL = BROKER_URL
SUPPORTED_TABLES = ["articles_openalex", "articles_oai"]

# =========================================
# üöÄ INITIALISATION CELERY
# =========================================
celery_app = Celery("sofa", broker=BROKER_URL, backend=BACKEND_URL)
celery_app.config_from_object("app.celeryconfig")

# =========================================
# üü¢ T√ÇCHES CELERY
# =========================================

@celery_app.task(name="pipeline.full")
def pipeline_full(limit_oai: int = 20):
    """Ex√©cute l‚Äôint√©gralit√© du pipeline (moissonnage, extraction, GROBID, NLP)."""
    logger.info("üöÄ [Celery] D√©marrage du pipeline complet")
    db = DatabaseManager()
    db.create_tables()
    try:
        run_full_pipeline(db, limit_oai)
        logger.info("‚úÖ Pipeline complet termin√©")
    except Exception as e:
        logger.exception(f"‚ùå Erreur pipeline complet : {e}")
    finally:
        db.close()

@celery_app.task(name="moissonner.articles")
def moissonner():
    """Moissonne OpenAlex + OAI-PMH et ins√®re en base"""
    logger.info("üöÄ [Celery] D√©marrage du moissonnage")
    try:
        db = DatabaseManager()
        db.create_tables()
        fetch_openalex_articles(db)
        fetch_oai_pmh_articles(db)
        logger.info("‚úÖ [Celery] Moissonnage termin√©")
    except Exception as e:
        logger.exception("‚ùå [Celery] Erreur pendant le moissonnage : %s", e)
    finally:
        if 'db' in locals():
            db.close()

@celery_app.task(name="reanalyser.batch")
def reanalyser_articles_nlp(table="articles_openalex", limit=100):
    """R√©analyse NLP sur les articles avec texte complet"""
    logger.info(f"üß† [Celery] R√©analyse NLP batch sur {table} (max {limit})")
    try:
        if table not in SUPPORTED_TABLES:
            raise ValueError(f"Table non support√©e : {table}")
        db = DatabaseManager()
        results = reanalyser_tous_les_articles(table, db, limite=limit)
        logger.info(f"‚úÖ [Celery] R√©analyse NLP termin√©e ({len(results)} articles)")
        return results
    except Exception as e:
        logger.error(f"‚ùå √âchec de la r√©analyse NLP : {e}")
        return {"error": str(e)}
    finally:
        if 'db' in locals():
            db.close()

@celery_app.task(name="grobid.batch")
def analyser_batch_grobid(limit: int = 20):
    """Analyse GROBID des PDFs non encore trait√©s"""
    from app.grobid import analyser_avec_grobid
    logger.info("üì¶ [Celery] Lancement batch GROBID sur les PDFs manquants")
    db = DatabaseManager()
    cur = db.cur
    cur.execute("""
        SELECT id, 'articles_oai' as source FROM articles_oai
        WHERE texte_complet IS NOT NULL AND id NOT IN (
            SELECT article_id FROM grobid_metadata WHERE source = 'articles_oai'
        )
        LIMIT %s
        UNION
        SELECT id, 'articles_openalex' as source FROM articles_openalex
        WHERE texte_complet IS NOT NULL AND id NOT IN (
            SELECT article_id FROM grobid_metadata WHERE source = 'articles_openalex'
        )
        LIMIT %s;
    """, (limit, limit))
    total = 0
    for article_id, source in cur.fetchall():
        try:
            analyser_avec_grobid(source, article_id, save=True)
            total += 1
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è GROBID √©chou√© pour {source} #{article_id} : {e}")
    db.close()
    logger.info(f"‚úÖ [Celery] GROBID batch termin√© ({total} articles analys√©s)")
    return {"total_analys√©s": total}

@celery_app.task(name="reanalyser.controverses.tei")
def reanalyser_controverses_tei():
    """R√©analyse des controverses depuis les TEI XML (GROBID)"""
    db = DatabaseManager()
    cur = db.cur
    cur.execute("SELECT article_id, source, tei_xml FROM grobid_metadata WHERE tei_xml IS NOT NULL;")
    total = 0
    for article_id, source, tei_xml in cur.fetchall():
        try:
            analyse = detecter_controverse_via_tei(tei_xml)
            cur.execute(
                """
                UPDATE grobid_metadata
                SET est_controverse_tei = %s,
                    score_controverse_tei = %s,
                    extrait_controverse_tei = %s
                WHERE article_id = %s AND source = %s;
                """,
                (
                    analyse["est_controverse"],
                    analyse["score"],
                    analyse["extrait"],
                    article_id,
                    source
                )
            )
            total += 1
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur TEI NLP pour {source} #{article_id} : {e}")
    db.conn.commit()
    db.close()
    logger.info(f"‚úÖ [Celery] R√©analyse TEI termin√©e ({total} articles)")
    return {"articles_analys√©s": total}

@celery_app.task(name="verifier.logs")
def verifier_logs():
    """T√¢che Celery : v√©rifie les erreurs dans les logs et d√©clenche une alerte si besoin."""
    from app.log_watcher import check_log_for_errors
    logger.info("üß™ [Celery] V√©rification automatique des logs (log_watcher)...")
    check_log_for_errors()
